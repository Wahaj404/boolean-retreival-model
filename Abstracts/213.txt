Acoustic Features for Recognizing Musical Artist Influence

music,feature extraction,data models,transforms,support vector machines,data mining

Musicologists have been interested in the topic of influence between composers for years and have developed methods and heuristics for recognizing influence in classical music. While these methods work well for music where the score is the primary source of information, this type of analysis is not well suited for modern popular music where the audio recording itself is arguably the primary representation. This paper presents two audio content-based systems for influence recognition: a system using a spectral representation (Constant-q transform) and support vector machines and another system that obtains features by using a deep belief network and then logistic regression for classification. The system using the spectral representation provides a baseline for future comparisons and evidence to support the idea that influence recognition can be performed using information extracted from the audio signal. The other system attempts to improve performance by using a deep belief network to learn features useful for influence recognition by mapping data extracted from the audio signal to labeled influence data. A dataset of about 77,000 30-second audio clips, consisting of retail previews of popular music tracks was gathered for this work. These songs were chosen from expertly-labeled influence relationship information gathered by the editors of the AllMusic guide.